{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b6be34-b529-45b5-a0f9-f56ff8911bd9",
   "metadata": {},
   "source": [
    "# Análise Comparativa de Modelos\n",
    "\n",
    "Nesse notebook iremos olhar para os textos obtidos na primeira unidade para construir modelos de aprendizado de máquina. Para isso, precisaremos de algumas bibliotecas já conhecidas (*pandas, nltk, numpy*) e de outras novas, relacionadas à:\n",
    "- preparação dos dados: \n",
    "    - *CountVectorizer*, \n",
    "    - *TfidfVectorizer*,\n",
    "    - *TruncatedSVD*\n",
    "    - *StandardScaler*\n",
    "- aprendizagem em si: \n",
    "    - *LogisticRegression*, \n",
    "    - *KNeighborsClassifier*, \n",
    "    - *SVC*, \n",
    "    - *RandomForestClassifier*\n",
    "- construção da sequência de passos a realizar:\n",
    "    - *Pipeline*\n",
    "- avaliação e seleção dos modelos obtidos:\n",
    "    - *ShuffleSplit*,\n",
    "    - *cross_validate*\n",
    "    \n",
    "Algumas dessas funções serão explicadas adiante. Sigamos.\n",
    "\n",
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "542b5384-0a7a-4009-bd2d-bf6c6c8656d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/madson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import joblib\n",
    "from src.data import organize\n",
    "from itertools import product # produto cartesiano de duas listas sem precisar de for aninhados\n",
    "import pandas as pd # manipulação de dataframes\n",
    "import nltk # ferramentas p/ processamento de linguagem natural\n",
    "import numpy as np # manipulação de matrizes, funções matemáticas\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    ShuffleSplit, KFold, cross_validate, RandomizedSearchCV\n",
    ")\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914b1ad-d16a-4753-9e1b-c2a8a98e74e3",
   "metadata": {},
   "source": [
    "## Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf70b45f-1075-4258-956f-d9e9b450a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adquire dados do arquivo produzido na etapa anterior\n",
    "input_path = \"../data/interim/news.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Converte as colunas com texto em uma lista\n",
    "corpus = df.text.to_list()\n",
    "\n",
    "# Atribui os valores 1 para notícias verdadeiras e 0 para notícias falsas\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809f859-8c48-4ee0-a9f5-2665b03be073",
   "metadata": {},
   "source": [
    "## Conversão dos textos (Vetorizadores)\n",
    "\n",
    "### CountVectorizer\n",
    "\n",
    "Esse método de conversão cria uma matriz com a contagem de todas as palavras presentes em todos os textos considerados. Esse método também é chamado de Bag of Words, ou Saco de Palavras.\n",
    "\n",
    "![CountVectorizer](images/count-vectorizer.png)\n",
    "\n",
    "### TfidfVectorizer\n",
    "\n",
    "Esse método de conversão cria uma matriz que considera dois valores: TF e DF. TF ($tf_{i,j}$) é a contagem de uma palavra ($i$) no texto ($j$), tal como é calculada pelo CountVectorizer. Já DF ($df_{i}$) diz respeito à quantidade de textos em que aquela palavra aparece. No cálculo, o valor para uma dada palavra ($w_{i,j}$) é dado por:\n",
    "\n",
    "$ w_{i,j} = tf_{i,j} \\times log(\\frac{N}{df_{i}}) $\n",
    "\n",
    "Em que $N$ é o número total de documentos. Como $df_{i}$ está no denominador do logarítmo, trata-se de uma conversão que considera TF e o inverso de DF, iDF.\n",
    "\n",
    "![CountVectorizer](images/tfidf-vectorizer.png)\n",
    "\n",
    "Em ambos os casos, palavras comuns e sem importância semântica no idioma trabalhado devem ser removidas. Afinal, caso fossem consideradas na conversão TFiDF, as palavras \"de\" e \"desse\" no primeiro texto teriam o mesmo peso da palavra \"corrupção\" e \"suspeito\", com importância semântica superior.\n",
    "\n",
    "Aqui, optamos também por utilizar apenas as 1000 palavras mais frequentes em ambas as conversões, de modo a limitar o número de características para o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf09e2bd-e35e-4cef-8849-85397fb0d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0a6d1-c85c-4e5a-952a-8ebd72a042dd",
   "metadata": {},
   "source": [
    "## Modelos de Aprendizagem de Máquina\n",
    "\n",
    "### Regressão Logística\n",
    "\n",
    "A regressão logística, que é um modelo classificador, utiliza uma função logística para calcular as probabilidades de uma notícia ser falsa ou verdadeira. A função logística por trás deste modelo é uma curva sigmoide contendo as probabilidades de classificação em uma determinada categoria (notícia falsa ou verdadeira). A partir disso se encontra um valor limite dentro da curva para que então se obtenham as predições.\n",
    "\n",
    "### KNN\n",
    "\n",
    "Aqui a classificação das notícias em falsas ou verdadeira é feita com base nos K-vizinhos mais próximos (*K-Nearest Neighbors*) a ela. Se utilizamos $K = 10$ e dentre as 10 notícias mais próximas de uma notícia $i$ no nosso espaço dimensional, 6 são falsas e 4 são verdadeiras, esta notícia $i$ será classificada como falsa. No nosso caso utilizamos $K = 21$.\n",
    "\n",
    "### SVC\n",
    "\n",
    "O SVC é um *Support Vector Classifier*, isso é, um algoritmo de classificação que utiliza vetores (dados) como suporte para definir um hiperplano que separe dados de um grupo dos dados de outro grupo. No nosso caso, o SVC busca um hiperplano que separe as matrizes produzidas a partir de notícias falsas daquelas de notícias verdadeiras.\n",
    "\n",
    "O hiperplano pode ser obtido após uma transformação dos dados, na qual eles saem de seu espaço dimensional original, intrínseco, e são levados a um espaço dimensional superior. Essa transformação é feita através através de diversas fórmulas matemáticas para que então o hiperplano ideal - aquele que separa os dados com melhor margem - seja identificado; este é o chamado *kernel trick*.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "A *Random Forest*, uma floresta aleatória, é um método que faz uso de diversas Árvores de Decisão, *Decision Trees*. As árvores de decisão são aquelas que fazem sucessivas divisões nos dados utilizando as características disponíveis de modo a obter grupos que sejam o mais diferentes entre si e o mais coesos internamente. Exemplo de divisão para separação de grupos: textos que têm a palavra ministro e textos que não têm, textos contendo a palavra corrupção e textos que não tem.\n",
    "\n",
    "Contando então com várias árvores de decisão, a *Floresta*, é um classificador do tipo *ensemble*, pois considera diferentes predições finais para cada texto pelas diferentes árvores. A predição prevalente para um dado texto é então incorporada à saída da *Random Forest*. Como as árvores de decisão não são dependentes entre si, possuindo critérios próprios e não relacionados, a Random Forest minimiza o viés que viria do uso de uma única árvore, se tornando um modelo poderoso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5295aa6-a2e5-4bc0-b626-fa77a61e3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [{\n",
    "    'name': 'LR',\n",
    "    'model': LogisticRegression(solver='liblinear'),\n",
    "    'parameters':{\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C' : np.logspace(-4, 4, 10),\n",
    "    }\n",
    "},{\n",
    "    'name': 'KNN',\n",
    "    'model': KNeighborsClassifier(algorithm='kd_tree'),\n",
    "    'parameters': {\n",
    "        'n_neighbors': np.arange(3, 21, 2),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "        # 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "},{\n",
    "    'name': 'SVC',\n",
    "    'model': SVC(max_iter=10000, gamma='auto'),\n",
    "    'parameters':{\n",
    "        \"C\": [1, 10, 100, 1e3, 1e4, 1e5]\n",
    "    }\n",
    "},{\n",
    "    'name': 'RF',\n",
    "    'model': RandomForestClassifier(),\n",
    "    'parameters':{\n",
    "        'n_estimators': [200, 500],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth' : [4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'bootstrap': [True, False]\n",
    "    }    \n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141b3052-0571-4a2c-81a8-eb9bc009c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleciona os modelos c menor fit time\n",
    "# apagar quando for gerar e selecionar os modelos finais\n",
    "models = list(models[i] for i in [0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5795a-3cb4-4c7a-9be1-aba481d31f3a",
   "metadata": {},
   "source": [
    "## Redução de Dimensionalidade\n",
    "\n",
    "Quando trabalhamos com texto é natural que o resultado das transformações dos textos em vetores (CountVectorizer, TFiDFVectorizer, etc) seja uma matriz esparsa, pois grande parte das palavras NÃO estará presente em diversos textos. Desse modo, pode ser vantajoso aplicar uma redução de dimensionalidade. Na etapa de transformação, ficamos com mil *features*, referentes às ocorrências das palavras mais frequentes. \n",
    "\n",
    "Agora, usaremos a função TruncatedSVD para reduzir nossa matriz esparsa pela metade, ficando apenas com as ocorrências das 500 palavras menos esparsas dentre as 1000 mais frequentes. A decomposição em valores singulares (*singular value decomposition*, SVD) transforma a matriz recebida e a leva para um espaço dimensional menor, reduzindo o efeito de sinônimos e palavras similares, as quais são usadas de maneira alternada pelos textos.\n",
    "\n",
    "## Normalização\n",
    "\n",
    "Na normalização os valores são transformados de forma a escala das diferentes características, isso reduz as chances de superestimação ou subestimação de determinadas *features* em função de seus valores padrão. Aqui, foi empregada uma normalização do tipo Z ou padronização, que subtrai a média da distribuição do para cada valor e divide o resultado pelo desvio padrão para aquela característica. Essa é uma maneira de normalizar sem alterar a distribuição das features, seja qual for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20a6091-4dd7-4c95-b821-41008bdd7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = TruncatedSVD()\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b937107-ad12-44a3-b398-b1a100ef2fa1",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Para facilitar a comparação entre os modelos utilizamos a função *Pipeline*. O protocolo envolve produzir predições com todas as combinações de transformadores e todos os modelos de aprendizagem de máquina produzidos com os mesmos métodos de redução de dimensionalidade e normalização.\n",
    "\n",
    "## Validação Cruzada\n",
    "\n",
    "Para testar a robustez dos modelos, a validação cruzada foi feita sobre 10 divisões aleatórias dos dados, conservando 80% deles para o conjunto de treinamento e 20% para teste. Ao final, os escores de avaliação (acurácia, F1-score, **baba** e **bebe**) obtidos foram armazenados em uma variável *results* para posterior análise.\n",
    "\n",
    "### Acurácia\n",
    "\n",
    "Esta medida de avaliação considera os acertos que o modelo realizou, sejam eles ao classificar notícias falsas como falsas ou notícias verdadeiras como verdadeiras. Todos os acertos são computados e calculados em forma de porcentagem em relação ao número total de dados. Esta é uma métrica interessante quando ambas as categorias são igualmente importantes.\n",
    "\n",
    "### F1\n",
    "\n",
    "No nosso caso, como detector de notícias falsas, pode ser mais interessante, caso seja necessário, priorizar modelos que tenham melhor desempenho em corretamente rotular notícias falsas. Nesse caso, o *F1-score* é uma boa medida para a avaliação dos erros (falsos positivos e falsos negativos) e será dado pela média harmônica entre precisão e sensibilidade. No nosso caso:\n",
    "\n",
    "- Precisão\n",
    "> Proporção dada pelo # de notícias falsas corretamente classificadas como falsas e o # total de notícias classificadas como falsas.\n",
    "- Sensibilidade\n",
    "> Proporção dada pelo # de notícias corretamente classificadas como falsas dividido pelo # notícias realmente falsas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4ed80c-23de-43cd-8e99-ab9a7e80462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/textos_pre-processado.csv').sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98f22c5-530f-471a-b83a-d3155b2c7d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running text-LR\n",
      "running text-SVC\n",
      "running lemmatization_final_texts-LR\n",
      "running lemmatization_final_texts-SVC\n",
      "running stemming_final_texts-LR\n",
      "running stemming_final_texts-SVC\n"
     ]
    }
   ],
   "source": [
    "n_splits_cv = 2\n",
    "n_splits_cv_grid_search = 2\n",
    "model_scores = []\n",
    "\n",
    "dataset_names = ['text', 'lemmatization_final_texts', 'stemming_final_texts']\n",
    "for dataset_name in dataset_names:\n",
    "    # remover depois que o conjunto de dados estiver OK\n",
    "    if dataset_name == 'stemming_final_texts':\n",
    "        # transforma cada notícia de lista para string\n",
    "        corpus = df[dataset_name].apply(lambda x: ' '.join(eval(x))).to_list()\n",
    "    else:\n",
    "        corpus = df[dataset_name].to_list()\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(df.label)\n",
    "    for model in models:\n",
    "        approach_name = f\"{dataset_name}-{model['name']}\"\n",
    "        print(f\"running {approach_name}\")\n",
    "        param_grid = {\n",
    "            'vectorizer__tfidf__use_idf': [False, True],\n",
    "            'vectorizer__count__max_features': [1000, 2000],\n",
    "            'pca__n_components': [100, 200, 500],\n",
    "            **{f\"model__{key}\": value for key, value in model['parameters'].items()}\n",
    "        }\n",
    "        approach = Pipeline([\n",
    "            (\"vectorizer\", vectorizer),\n",
    "            (\"pca\", pca),\n",
    "            (\"normalize\", scaler),\n",
    "            ('model', model['model'])\n",
    "        ])\n",
    "\n",
    "        gs = RandomizedSearchCV(\n",
    "            estimator=approach,\n",
    "            param_distributions=param_grid,\n",
    "            scoring='f1',\n",
    "            cv=n_splits_cv_grid_search,\n",
    "            random_state=24\n",
    "        )\n",
    "\n",
    "        scores = cross_validate(\n",
    "            estimator=gs,\n",
    "            X=corpus,\n",
    "            y=labels,\n",
    "            cv=ShuffleSplit(n_splits=n_splits_cv, test_size=.2),\n",
    "            n_jobs=4,\n",
    "            scoring=['accuracy', 'precision', 'recall','f1', 'roc_auc'],\n",
    "        )\n",
    "        scores['model'] = [approach_name] * n_splits_cv\n",
    "        model_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee935b49-a6f9-49fc-a3cb-edc97c5dc6d1",
   "metadata": {},
   "source": [
    "## Comparação dos modelos\n",
    "### Tabela\n",
    "\n",
    "Em que os resultados são agrupados de acordo com os modelos e são calculadas média e desvio padrão dos dez modelos gerados para cada combinação vetorizador-método de aprendizagem de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75459c2-5944-489c-a29c-a5763bec1c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = organize.concatenate(*model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15c8b1f1-861a-4095-a381-23681e7fcc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6b697_row0_col3, #T_6b697_row1_col3, #T_6b697_row2_col1, #T_6b697_row3_col1, #T_6b697_row4_col6, #T_6b697_row5_col1, #T_6b697_row6_col2 {\n",
       "  color: white;\n",
       "  background-color: gray;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6b697\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_6b697_level0_col0\" class=\"col_heading level0 col0\" >score</th>\n",
       "      <th id=\"T_6b697_level0_col1\" class=\"col_heading level0 col1\" >lemmatization_final_texts-LR</th>\n",
       "      <th id=\"T_6b697_level0_col2\" class=\"col_heading level0 col2\" >lemmatization_final_texts-SVC</th>\n",
       "      <th id=\"T_6b697_level0_col3\" class=\"col_heading level0 col3\" >stemming_final_texts-LR</th>\n",
       "      <th id=\"T_6b697_level0_col4\" class=\"col_heading level0 col4\" >stemming_final_texts-SVC</th>\n",
       "      <th id=\"T_6b697_level0_col5\" class=\"col_heading level0 col5\" >text-LR</th>\n",
       "      <th id=\"T_6b697_level0_col6\" class=\"col_heading level0 col6\" >text-SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_6b697_row0_col0\" class=\"data row0 col0\" >fit_time</td>\n",
       "      <td id=\"T_6b697_row0_col1\" class=\"data row0 col1\" >9.876 ± 0.079</td>\n",
       "      <td id=\"T_6b697_row0_col2\" class=\"data row0 col2\" >11.410 ± 0.244</td>\n",
       "      <td id=\"T_6b697_row0_col3\" class=\"data row0 col3\" >9.235 ± 0.426</td>\n",
       "      <td id=\"T_6b697_row0_col4\" class=\"data row0 col4\" >11.034 ± 0.183</td>\n",
       "      <td id=\"T_6b697_row0_col5\" class=\"data row0 col5\" >14.412 ± 0.021</td>\n",
       "      <td id=\"T_6b697_row0_col6\" class=\"data row0 col6\" >13.458 ± 0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6b697_row1_col0\" class=\"data row1 col0\" >score_time</td>\n",
       "      <td id=\"T_6b697_row1_col1\" class=\"data row1 col1\" >0.122 ± 0.018</td>\n",
       "      <td id=\"T_6b697_row1_col2\" class=\"data row1 col2\" >0.182 ± 0.021</td>\n",
       "      <td id=\"T_6b697_row1_col3\" class=\"data row1 col3\" >0.097 ± 0.016</td>\n",
       "      <td id=\"T_6b697_row1_col4\" class=\"data row1 col4\" >0.165 ± 0.024</td>\n",
       "      <td id=\"T_6b697_row1_col5\" class=\"data row1 col5\" >0.200 ± 0.002</td>\n",
       "      <td id=\"T_6b697_row1_col6\" class=\"data row1 col6\" >0.206 ± 0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6b697_row2_col0\" class=\"data row2 col0\" >test_accuracy</td>\n",
       "      <td id=\"T_6b697_row2_col1\" class=\"data row2 col1\" >0.950 ± 0.000</td>\n",
       "      <td id=\"T_6b697_row2_col2\" class=\"data row2 col2\" >0.945 ± 0.015</td>\n",
       "      <td id=\"T_6b697_row2_col3\" class=\"data row2 col3\" >0.915 ± 0.035</td>\n",
       "      <td id=\"T_6b697_row2_col4\" class=\"data row2 col4\" >0.680 ± 0.200</td>\n",
       "      <td id=\"T_6b697_row2_col5\" class=\"data row2 col5\" >0.925 ± 0.005</td>\n",
       "      <td id=\"T_6b697_row2_col6\" class=\"data row2 col6\" >0.890 ± 0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6b697_row3_col0\" class=\"data row3 col0\" >test_precision</td>\n",
       "      <td id=\"T_6b697_row3_col1\" class=\"data row3 col1\" >0.931 ± 0.029</td>\n",
       "      <td id=\"T_6b697_row3_col2\" class=\"data row3 col2\" >0.930 ± 0.013</td>\n",
       "      <td id=\"T_6b697_row3_col3\" class=\"data row3 col3\" >0.906 ± 0.038</td>\n",
       "      <td id=\"T_6b697_row3_col4\" class=\"data row3 col4\" >0.633 ± 0.175</td>\n",
       "      <td id=\"T_6b697_row3_col5\" class=\"data row3 col5\" >0.903 ± 0.017</td>\n",
       "      <td id=\"T_6b697_row3_col6\" class=\"data row3 col6\" >0.805 ± 0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6b697_row4_col0\" class=\"data row4 col0\" >test_recall</td>\n",
       "      <td id=\"T_6b697_row4_col1\" class=\"data row4 col1\" >0.971 ± 0.029</td>\n",
       "      <td id=\"T_6b697_row4_col2\" class=\"data row4 col2\" >0.958 ± 0.022</td>\n",
       "      <td id=\"T_6b697_row4_col3\" class=\"data row4 col3\" >0.894 ± 0.069</td>\n",
       "      <td id=\"T_6b697_row4_col4\" class=\"data row4 col4\" >0.963 ± 0.037</td>\n",
       "      <td id=\"T_6b697_row4_col5\" class=\"data row4 col5\" >0.934 ± 0.005</td>\n",
       "      <td id=\"T_6b697_row4_col6\" class=\"data row4 col6\" >0.976 ± 0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6b697_row5_col0\" class=\"data row5 col0\" >test_f1</td>\n",
       "      <td id=\"T_6b697_row5_col1\" class=\"data row5 col1\" >0.949 ± 0.001</td>\n",
       "      <td id=\"T_6b697_row5_col2\" class=\"data row5 col2\" >0.944 ± 0.018</td>\n",
       "      <td id=\"T_6b697_row5_col3\" class=\"data row5 col3\" >0.900 ± 0.054</td>\n",
       "      <td id=\"T_6b697_row5_col4\" class=\"data row5 col4\" >0.746 ± 0.118</td>\n",
       "      <td id=\"T_6b697_row5_col5\" class=\"data row5 col5\" >0.918 ± 0.011</td>\n",
       "      <td id=\"T_6b697_row5_col6\" class=\"data row5 col6\" >0.882 ± 0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_6b697_row6_col0\" class=\"data row6 col0\" >test_roc_auc</td>\n",
       "      <td id=\"T_6b697_row6_col1\" class=\"data row6 col1\" >0.981 ± 0.006</td>\n",
       "      <td id=\"T_6b697_row6_col2\" class=\"data row6 col2\" >0.985 ± 0.010</td>\n",
       "      <td id=\"T_6b697_row6_col3\" class=\"data row6 col3\" >0.963 ± 0.016</td>\n",
       "      <td id=\"T_6b697_row6_col4\" class=\"data row6 col4\" >0.941 ± 0.017</td>\n",
       "      <td id=\"T_6b697_row6_col5\" class=\"data row6 col5\" >0.972 ± 0.005</td>\n",
       "      <td id=\"T_6b697_row6_col6\" class=\"data row6 col6\" >0.966 ± 0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7119e95f40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O melhor modelo é o lemmatization_final_texts-LR\n"
     ]
    }
   ],
   "source": [
    "results = (\n",
    "    pd\n",
    "    .DataFrame(scores)\n",
    "    .groupby(['model'])\n",
    "    .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])#\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"score\"})\n",
    "    .drop(columns=\"level_1\")\n",
    "    # .set_index('score')\n",
    ")\n",
    "time_scores = ['fit_time', 'score_time']\n",
    "get_winner = partial(organize.get_winner, models=results.columns[1:])\n",
    "winner = (\n",
    "    results\n",
    "    .query('score not in @time_scores')\n",
    "    .apply(get_winner, axis=1)\n",
    "    .value_counts()\n",
    "    .index[0]\n",
    ")\n",
    "results.columns.name = ''\n",
    "results = (\n",
    "    results\n",
    "    .style\n",
    "    .hide(axis='index')\n",
    "    .apply(organize.highlight_max, props='color:white;background-color:gray', axis=1)\n",
    ")\n",
    "display(results)\n",
    "print(f'O melhor modelo é o {winner}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2641f9-d991-4f60-9089-121b010c0b2e",
   "metadata": {},
   "source": [
    "Nesta tabela temos informações relacionadas a:\n",
    "- **Fit Time**: Tempo gasto na adequação do modelo ao conjunto de treino.\n",
    "- **Score Time**: Tempo gasto para avaliação do modelo com o conjunto teste.\n",
    "- **Test Accuracy**: Acurácia do modelo frente ao conjunto teste.\n",
    "- **Test F1**: F1 score do modelo frente ao conjunto teste.\n",
    "\n",
    "As linhas que computam a média dessas métricas estão coloridas de acordo com os valores, quão maiores, mais escuro o fundo da célula na tabela. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f44cb2-fb4e-4418-9d06-7579d394dcdd",
   "metadata": {},
   "source": [
    "### Figura\n",
    "\n",
    "Para produzir a figura os dados provenientes dos resultados passaram por uma pequena modificação para que cada método de aprendizado e cada vetorizador ficasse em uma coluna específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb57d5d9-0256-4cfd-974f-3b3cee59abde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_label_encoder.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = next(item for item in models if item[\"name\"] == winner.split(\"-\")[-1])\n",
    "best_dataset_name = winner.split(\"-\")[0]\n",
    "\n",
    "# remover depois que o conjunto de dados estiver OK\n",
    "if best_dataset_name == 'stemming_final_texts':\n",
    "    # transforma cada notícia de lista para string\n",
    "    corpus = df[best_dataset_name].apply(lambda x: ' '.join(eval(x))).to_list()\n",
    "else:\n",
    "    corpus = df[best_dataset_name].to_list()\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df.label)\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer__tfidf__use_idf': [False, True],\n",
    "    'vectorizer__count__max_features': [1000, 2000],\n",
    "    'pca__n_components': [100, 200, 500],\n",
    "    **{f\"model__{key}\": value for key, value in best_model['parameters'].items()}\n",
    "}\n",
    "approach = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"pca\", pca),\n",
    "    (\"normalize\", scaler),\n",
    "    ('model', best_model['model'])\n",
    "])\n",
    "\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=approach,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=n_splits_cv_grid_search,\n",
    "    random_state=24\n",
    ")\n",
    "\n",
    "gs.fit(corpus, labels)\n",
    "\n",
    "model_path = \"../models/best_model.joblib\"\n",
    "label_transformer_path = \"../models/best_label_encoder.joblib\"\n",
    "\n",
    "joblib.dump(gs.best_estimator_, model_path)\n",
    "joblib.dump(label_encoder, label_transformer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df1aa2d-5f8c-4ae0-977c-8ad176ce1451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.432956</td>\n",
       "      <td>0.197516</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.976791</td>\n",
       "      <td>text-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.390236</td>\n",
       "      <td>0.202410</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.967570</td>\n",
       "      <td>text-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.765407</td>\n",
       "      <td>0.175789</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.974838</td>\n",
       "      <td>text-SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.150230</td>\n",
       "      <td>0.236335</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.956594</td>\n",
       "      <td>text-SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.797243</td>\n",
       "      <td>0.139858</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.974790</td>\n",
       "      <td>lemmatization_final_texts-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.955135</td>\n",
       "      <td>0.103459</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.986715</td>\n",
       "      <td>lemmatization_final_texts-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.653642</td>\n",
       "      <td>0.161359</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.975110</td>\n",
       "      <td>lemmatization_final_texts-SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.166110</td>\n",
       "      <td>0.202998</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.995198</td>\n",
       "      <td>lemmatization_final_texts-SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.808567</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.979526</td>\n",
       "      <td>stemming_final_texts-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.661433</td>\n",
       "      <td>0.081264</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>stemming_final_texts-LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.216925</td>\n",
       "      <td>0.140698</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.957834</td>\n",
       "      <td>stemming_final_texts-SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.850613</td>\n",
       "      <td>0.189572</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.924513</td>\n",
       "      <td>stemming_final_texts-SVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "0   14.432956    0.197516           0.93        0.920000     0.938776   \n",
       "1   14.390236    0.202410           0.92        0.886364     0.928571   \n",
       "2   13.765407    0.175789           0.90        0.814815     1.000000   \n",
       "3   13.150230    0.236335           0.88        0.795918     0.951220   \n",
       "4    9.797243    0.139858           0.95        0.960000     0.941176   \n",
       "5    9.955135    0.103459           0.95        0.901961     1.000000   \n",
       "6   11.653642    0.161359           0.93        0.916667     0.936170   \n",
       "7   11.166110    0.202998           0.96        0.943396     0.980392   \n",
       "8    8.808567    0.113419           0.95        0.944444     0.962264   \n",
       "9    9.661433    0.081264           0.88        0.868421     0.825000   \n",
       "10  11.216925    0.140698           0.88        0.808511     0.926829   \n",
       "11  10.850613    0.189572           0.48        0.458333     1.000000   \n",
       "\n",
       "     test_f1  test_roc_auc                          model  \n",
       "0   0.929293      0.976791                        text-LR  \n",
       "1   0.906977      0.967570                        text-LR  \n",
       "2   0.897959      0.974838                       text-SVC  \n",
       "3   0.866667      0.956594                       text-SVC  \n",
       "4   0.950495      0.974790   lemmatization_final_texts-LR  \n",
       "5   0.948454      0.986715   lemmatization_final_texts-LR  \n",
       "6   0.926316      0.975110  lemmatization_final_texts-SVC  \n",
       "7   0.961538      0.995198  lemmatization_final_texts-SVC  \n",
       "8   0.953271      0.979526        stemming_final_texts-LR  \n",
       "9   0.846154      0.946667        stemming_final_texts-LR  \n",
       "10  0.863636      0.957834       stemming_final_texts-SVC  \n",
       "11  0.628571      0.924513       stemming_final_texts-SVC  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = (\n",
    "    pd\n",
    "    .DataFrame(scores)\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "358158a2-e76a-4c0c-b33b-323659598f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,8))\n",
    "fig.suptitle('Acurácia e Escore F1 dos modelos', fontsize=16)\n",
    "\n",
    "sns.barplot(x=\"model\", y=\"test_accuracy\", palette=\"colorblind\",\n",
    "            data=results_df, ax=ax1)\n",
    "ax1.set_title(\"Acurácia\")\n",
    "ax1.set(xlabel=None, ylabel=None)\n",
    "\n",
    "sns.barplot(x=\"model\", y=\"test_f1\", palette=\"colorblind\",\n",
    "            data=results_df, ax=ax2)\n",
    "ax2.set_title(\"F1-Score\")\n",
    "ax2.set(xlabel=None, ylabel=None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a4296-ee29-4730-88a7-5962e695d392",
   "metadata": {},
   "source": [
    "Os gráficos do tipo violino exibem a distribuição métricas de avaliação explicadas em detalhe mais acima. Conforme também visto na tabela,a acurácia da maioria dos modelos se encontra acima de 90%. Isso vale para todos os modelos da validação cruzada feito para a Regressão Logística, o Classificador com Vetores de Suporte e a Random Forest. Esses métodos também mostraram bom desempenho em relação ao F1-Score, com valores acima de 0.91. \n",
    "\n",
    "A exceção de desempenho é vista para os modelos gerados com o método dos K Vizinhos Mais Próximos, o KNN. Esse método mostrou baixa acurácia, de cerca de 0.5 utilizando ambos os vetorizadores. Já o F1-Score, apesar de baixo para ambos, foi discrepante a depender do vetorizador. O modelo KNN que utilizou o vetorizador de contagem simples (bag of words, saco de palavras) teve F1-Score próximo a zero. Já o modelo que utilizou o vetorizador TFiDF, que considera também a quantidade de textos em que uma palavra aparece,atingiu um F1-Score de cerca de 0.67."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

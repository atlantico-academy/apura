{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b6be34-b529-45b5-a0f9-f56ff8911bd9",
   "metadata": {},
   "source": [
    "# Análise Comparativa de Modelos\n",
    "\n",
    "Nesse notebook iremos olhar para os textos obtidos na primeira unidade para construir modelos de aprendizado de máquina. Para isso, precisaremos de algumas bibliotecas já conhecidas (*pandas, nltk, numpy*) e de outras novas, relacionadas à:\n",
    "- preparação dos dados: \n",
    "    - *CountVectorizer*, \n",
    "    - *TfidfVectorizer*,\n",
    "    - *TruncatedSVD*\n",
    "    - *StandardScaler*\n",
    "- aprendizagem em si: \n",
    "    - *LogisticRegression*, \n",
    "    - *KNeighborsClassifier*, \n",
    "    - *SVC*, \n",
    "    - *RandomForestClassifier*\n",
    "- construção da sequência de passos a realizar:\n",
    "    - *Pipeline*\n",
    "- avaliação e seleção dos modelos obtidos:\n",
    "    - *ShuffleSplit*,\n",
    "    - *cross_validate*\n",
    "    \n",
    "Algumas dessas funções serão explicadas adiante. Sigamos.\n",
    "\n",
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542b5384-0a7a-4009-bd2d-bf6c6c8656d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/samya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product # produto cartesiano de duas listas sem precisar de for aninhados\n",
    "import pandas as pd # manipulação de dataframes\n",
    "import nltk # ferramentas p/ processamento de linguagem natural\n",
    "import numpy as np # manipulação de matrizes, funções matemáticas\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    ShuffleSplit, KFold, cross_validate, RandomizedSearchCV\n",
    ")\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914b1ad-d16a-4753-9e1b-c2a8a98e74e3",
   "metadata": {},
   "source": [
    "## Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf70b45f-1075-4258-956f-d9e9b450a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adquire dados do arquivo produzido na etapa anterior\n",
    "input_path = \"../data/interim/news.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Converte as colunas com texto em uma lista\n",
    "corpus = df.text.to_list()\n",
    "\n",
    "# Atribui os valores 1 para notícias verdadeiras e 0 para notícias falsas\n",
    "labels = df.label.replace({\"true\": 1, \"fake\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809f859-8c48-4ee0-a9f5-2665b03be073",
   "metadata": {},
   "source": [
    "## Conversão dos textos (Vetorizadores)\n",
    "\n",
    "### CountVectorizer\n",
    "\n",
    "Esse método de conversão cria uma matriz com a contagem de todas as palavras presentes em todos os textos considerados. Esse método também é chamado de Bag of Words, ou Saco de Palavras.\n",
    "\n",
    "![CountVectorizer](images/count-vectorizer.png)\n",
    "\n",
    "### TfidfVectorizer\n",
    "\n",
    "Esse método de conversão cria uma matriz que considera dois valores: TF e DF. TF ($tf_{i,j}$) é a contagem de uma palavra ($i$) no texto ($j$), tal como é calculada pelo CountVectorizer. Já DF ($df_{i}$) diz respeito à quantidade de textos em que aquela palavra aparece. No cálculo, o valor para uma dada palavra ($w_{i,j}$) é dado por:\n",
    "\n",
    "$ w_{i,j} = tf_{i,j} \\times log(\\frac{N}{df_{i}}) $\n",
    "\n",
    "Em que $N$ é o número total de documentos. Como $df_{i}$ está no denominador do logarítmo, trata-se de uma conversão que considera TF e o inverso de DF, iDF.\n",
    "\n",
    "![CountVectorizer](images/tfidf-vectorizer.png)\n",
    "\n",
    "Em ambos os casos, palavras comuns e sem importância semântica no idioma trabalhado devem ser removidas. Afinal, caso fossem consideradas na conversão TFiDF, as palavras \"de\" e \"desse\" no primeiro texto teriam o mesmo peso da palavra \"corrupção\" e \"suspeito\", com importância semântica superior.\n",
    "\n",
    "Aqui, optamos também por utilizar apenas as 1000 palavras mais frequentes em ambas as conversões, de modo a limitar o número de características para o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf09e2bd-e35e-4cef-8849-85397fb0d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "vectorizer = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0a6d1-c85c-4e5a-952a-8ebd72a042dd",
   "metadata": {},
   "source": [
    "## Modelos de Aprendizagem de Máquina\n",
    "\n",
    "### Regressão Logística\n",
    "\n",
    "A regressão logística, que é um modelo classificador, utiliza uma função logística para calcular as probabilidades de uma notícia ser falsa ou verdadeira. A função logística por trás deste modelo é uma curva sigmoide contendo as probabilidades de classificação em uma determinada categoria (notícia falsa ou verdadeira). A partir disso se encontra um valor limite dentro da curva para que então se obtenham as predições.\n",
    "\n",
    "### KNN\n",
    "\n",
    "Aqui a classificação das notícias em falsas ou verdadeira é feita com base nos K-vizinhos mais próximos (*K-Nearest Neighbors*) a ela. Se utilizamos $K = 10$ e dentre as 10 notícias mais próximas de uma notícia $i$ no nosso espaço dimensional, 6 são falsas e 4 são verdadeiras, esta notícia $i$ será classificada como falsa. No nosso caso utilizamos $K = 21$.\n",
    "\n",
    "### SVC\n",
    "\n",
    "O SVC é um *Support Vector Classifier*, isso é, um algoritmo de classificação que utiliza vetores (dados) como suporte para definir um hiperplano que separe dados de um grupo dos dados de outro grupo. No nosso caso, o SVC busca um hiperplano que separe as matrizes produzidas a partir de notícias falsas daquelas de notícias verdadeiras.\n",
    "\n",
    "O hiperplano pode ser obtido após uma transformação dos dados, na qual eles saem de seu espaço dimensional original, intrínseco, e são levados a um espaço dimensional superior. Essa transformação é feita através através de diversas fórmulas matemáticas para que então o hiperplano ideal - aquele que separa os dados com melhor margem - seja identificado; este é o chamado *kernel trick*.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "A *Random Forest*, uma floresta aleatória, é um método que faz uso de diversas Árvores de Decisão, *Decision Trees*. As árvores de decisão são aquelas que fazem sucessivas divisões nos dados utilizando as características disponíveis de modo a obter grupos que sejam o mais diferentes entre si e o mais coesos internamente. Exemplo de divisão para separação de grupos: textos que têm a palavra ministro e textos que não têm, textos contendo a palavra corrupção e textos que não tem.\n",
    "\n",
    "Contando então com várias árvores de decisão, a *Floresta*, é um classificador do tipo *ensemble*, pois considera diferentes predições finais para cada texto pelas diferentes árvores. A predição prevalente para um dado texto é então incorporada à saída da *Random Forest*. Como as árvores de decisão não são dependentes entre si, possuindo critérios próprios e não relacionados, a Random Forest minimiza o viés que viria do uso de uma única árvore, se tornando um modelo poderoso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5295aa6-a2e5-4bc0-b626-fa77a61e3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [{\n",
    "    'name': 'LR',\n",
    "    'model': LogisticRegression(),\n",
    "    'parameters':{\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C' : np.logspace(-4, 4, 10),\n",
    "    }\n",
    "},{\n",
    "    'name': 'KNN',\n",
    "    'model': KNeighborsClassifier(),\n",
    "    'parameters': {\n",
    "        'n_neighbors': np.arange(3, 21, 2),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    }\n",
    "},{\n",
    "    'name': 'SVC',\n",
    "    'model': SVC(max_iter=10000, gamma='auto'),\n",
    "    'parameters':{\n",
    "        \"C\": [1, 10, 100, 1e3, 1e4, 1e5]\n",
    "    }\n",
    "},{\n",
    "    'name': 'RF',\n",
    "    'model': RandomForestClassifier(),\n",
    "    'parameters':{\n",
    "        'n_estimators': [200, 500],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth' : [4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy'],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'bootstrap': [True, False]\n",
    "    }    \n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5795a-3cb4-4c7a-9be1-aba481d31f3a",
   "metadata": {},
   "source": [
    "## Redução de Dimensionalidade\n",
    "\n",
    "Quando trabalhamos com texto é natural que o resultado das transformações dos textos em vetores (CountVectorizer, TFiDFVectorizer, etc) seja uma matriz esparsa, pois grande parte das palavras NÃO estará presente em diversos textos. Desse modo, pode ser vantajoso aplicar uma redução de dimensionalidade. Na etapa de transformação, ficamos com mil *features*, referentes às ocorrências das palavras mais frequentes. \n",
    "\n",
    "Agora, usaremos a função TruncatedSVD para reduzir nossa matriz esparsa pela metade, ficando apenas com as ocorrências das 500 palavras menos esparsas dentre as 1000 mais frequentes. A decomposição em valores singulares (*singular value decomposition*, SVD) transforma a matriz recebida e a leva para um espaço dimensional menor, reduzindo o efeito de sinônimos e palavras similares, as quais são usadas de maneira alternada pelos textos.\n",
    "\n",
    "## Normalização\n",
    "\n",
    "Na normalização os valores são transformados de forma a escala das diferentes características, isso reduz as chances de superestimação ou subestimação de determinadas *features* em função de seus valores padrão. Aqui, foi empregada uma normalização do tipo Z ou padronização, que subtrai a média da distribuição do para cada valor e divide o resultado pelo desvio padrão para aquela característica. Essa é uma maneira de normalizar sem alterar a distribuição das features, seja qual for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20a6091-4dd7-4c95-b821-41008bdd7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = TruncatedSVD()\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b937107-ad12-44a3-b398-b1a100ef2fa1",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Para facilitar a comparação entre os modelos utilizamos a função *Pipeline*. O protocolo envolve produzir predições com todas as combinações de transformadores e todos os modelos de aprendizagem de máquina produzidos com os mesmos métodos de redução de dimensionalidade e normalização.\n",
    "\n",
    "## Validação Cruzada\n",
    "\n",
    "Para testar a robustez dos modelos, a validação cruzada foi feita sobre 10 divisões aleatórias dos dados, conservando 80% deles para o conjunto de treinamento e 20% para teste. Ao final, os escores de avaliação (acurácia, F1-score, **baba** e **bebe**) obtidos foram armazenados em uma variável *results* para posterior análise.\n",
    "\n",
    "### Acurácia\n",
    "\n",
    "Esta medida de avaliação considera os acertos que o modelo realizou, sejam eles ao classificar notícias falsas como falsas ou notícias verdadeiras como verdadeiras. Todos os acertos são computados e calculados em forma de porcentagem em relação ao número total de dados. Esta é uma métrica interessante quando ambas as categorias são igualmente importantes.\n",
    "\n",
    "### F1\n",
    "\n",
    "No nosso caso, como detector de notícias falsas, pode ser mais interessante, caso seja necessário, priorizar modelos que tenham melhor desempenho em corretamente rotular notícias falsas. Nesse caso, o *F1-score* é uma boa medida para a avaliação dos erros (falsos positivos e falsos negativos) e será dado pela média harmônica entre precisão e sensibilidade. No nosso caso:\n",
    "\n",
    "- Precisão\n",
    "> Proporção dada pelo # de notícias falsas corretamente classificadas como falsas e o # total de notícias classificadas como falsas.\n",
    "- Sensibilidade\n",
    "> Proporção dada pelo # de notícias corretamente classificadas como falsas dividido pelo # notícias realmente falsas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7e46c1-96a2-4dfc-a337-1782d58a6439",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m n_splits_gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      5\u001b[0m split_cv \u001b[38;5;241m=\u001b[39m ShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39mn_splits_cv, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.2\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model_ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[1;32m      8\u001b[0m     model_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m params[model_name]\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     10\u001b[0m     }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "n_splits_cv = 10\n",
    "n_splits_gs = 5\n",
    "\n",
    "split_cv = ShuffleSplit(n_splits=n_splits_cv, test_size=.2)\n",
    "for model_name, model_ in models.items():\n",
    "    print(model_name)\n",
    "    model_params = {\n",
    "        f'model__{key}': value for key, value in params[model_name].items()\n",
    "    }\n",
    "    param_distributions = {\n",
    "        'vectorizer__tfidf__use_idf': [False, True],\n",
    "        'vectorizer__count__max_features': [1000, 2000],\n",
    "        'pca__n_components': [100, 200, 500],\n",
    "        **model_params\n",
    "    }\n",
    "    print()\n",
    "    print(param_distributions)\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"pca\", pca),\n",
    "        (\"normalize\", scaler),\n",
    "        (\"model\", model_)\n",
    "    ])\n",
    "    gs_model = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions,\n",
    "        scoring='f1',\n",
    "        cv=n_splits_gs,\n",
    "        refit=True,\n",
    "        error_score='raise'\n",
    "    )\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        gs_model,\n",
    "        corpus,\n",
    "        labels,\n",
    "        cv=n_splits_cv,\n",
    "        scoring=['accuracy', 'f1']\n",
    "    )\n",
    "    scores['model'] = [f\"{model_name}\"] * n_splits_cv\n",
    "    if not(results):\n",
    "        results = {key: [] for key in scores}\n",
    "    for key in scores:\n",
    "        results[key].extend(scores[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee935b49-a6f9-49fc-a3cb-edc97c5dc6d1",
   "metadata": {},
   "source": [
    "## Comparação dos modelos\n",
    "### Tabela\n",
    "\n",
    "Em que os resultados são agrupados de acordo com os modelos e são calculadas média e desvio padrão dos dez modelos gerados para cada combinação vetorizador-método de aprendizagem de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a83c2-31aa-4711-91f0-137db8068ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bececb25-cd41-4bb0-bd7c-01b2d40ff34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = (\n",
    "    pd\n",
    "    .DataFrame(results)\n",
    "    .groupby(\"model\")\n",
    "    .agg([np.mean, np.std])\n",
    "    .transpose()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2641f9-d991-4f60-9089-121b010c0b2e",
   "metadata": {},
   "source": [
    "Nesta tabela temos informações relacionadas a:\n",
    "- **Fit Time**: Tempo gasto na adequação do modelo ao conjunto de treino.\n",
    "- **Score Time**: Tempo gasto para avaliação do modelo com o conjunto teste.\n",
    "- **Test Accuracy**: Acurácia do modelo frente ao conjunto teste.\n",
    "- **Test F1**: F1 score do modelo frente ao conjunto teste.\n",
    "\n",
    "As linhas que computam a média dessas métricas estão coloridas de acordo com os valores, quão maiores, mais escuro o fundo da célula na tabela. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f949d9-2d5e-49af-85a8-0b0e2cad63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "slice_ = idx[idx[:,'mean'], :]\n",
    "df_results.style.background_gradient(axis=1, subset=slice_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f44cb2-fb4e-4418-9d06-7579d394dcdd",
   "metadata": {},
   "source": [
    "### Figura\n",
    "\n",
    "Para produzir a figura os dados provenientes dos resultados passaram por uma pequena modificação para que cada método de aprendizado e cada vetorizador ficasse em uma coluna específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1317c5-6ca4-4ff0-bf5f-9762cf30f953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = (\n",
    "    pd\n",
    "    .DataFrame(results)\n",
    ")\n",
    "results_df[['vectorizer', 'method']] = results_df['model'].str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358158a2-e76a-4c0c-b33b-323659598f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,8))\n",
    "\n",
    "sns.violinplot(x=\"method\", y=\"test_accuracy\", hue=\"vectorizer\", \n",
    "               palette=\"colorblind\", data=results_df, cut=0, ax=ax1)\n",
    "ax1.set_title(\"Acurácia\")\n",
    "ax1.set_xlabel(\"Modelo de Predição\")\n",
    "ax1.set_ylabel(\"Acurácia dos conjuntos de teste\")\n",
    "ax1.legend(title=\"Vetorizador\")\n",
    "\n",
    "sns.violinplot(x=\"method\", y=\"test_f1\", hue=\"vectorizer\", \n",
    "               palette=\"colorblind\", data=results_df, cut=0, ax=ax2)\n",
    "ax2.set_title(\"Comparação F1-Score\")\n",
    "ax2.set_xlabel(\"Modelo de Predição\")\n",
    "ax2.set_ylabel(\"F1-Score dos conjuntos de teste\")\n",
    "ax2.legend(title=\"Vetorizador\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a4296-ee29-4730-88a7-5962e695d392",
   "metadata": {},
   "source": [
    "Os gráficos do tipo violino exibem a distribuição métricas de avaliação explicadas em detalhe mais acima. Conforme também visto na tabela,a acurácia da maioria dos modelos se encontra acima de 90%. Isso vale para todos os modelos da validação cruzada feito para a Regressão Logística, o Classificador com Vetores de Suporte e a Random Forest. Esses métodos também mostraram bom desempenho em relação ao F1-Score, com valores acima de 0.91. \n",
    "\n",
    "A exceção de desempenho é vista para os modelos gerados com o método dos K Vizinhos Mais Próximos, o KNN. Esse método mostrou baixa acurácia, de cerca de 0.5 utilizando ambos os vetorizadores. Já o F1-Score, apesar de baixo para ambos, foi discrepante a depender do vetorizador. O modelo KNN que utilizou o vetorizador de contagem simples (bag of words, saco de palavras) teve F1-Score próximo a zero. Já o modelo que utilizou o vetorizador TFiDF, que considera também a quantidade de textos em que uma palavra aparece,atingiu um F1-Score de cerca de 0.67."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

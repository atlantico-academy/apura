{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b6be34-b529-45b5-a0f9-f56ff8911bd9",
   "metadata": {},
   "source": [
    "# Análise Comparativa de Modelos\n",
    "\n",
    "Nesse notebook iremos olhar para os textos obtidos na primeira unidade para construir modelos de aprendizado de máquina. Para isso, precisaremos de algumas bibliotecas já conhecidas (*pandas, nltk, numpy*) e de outras novas, relacionadas à:\n",
    "- preparação dos dados: \n",
    "    - *CountVectorizer*, \n",
    "    - *TfidfVectorizer*,\n",
    "    - *TruncatedSVD*\n",
    "    - *StandardScaler*\n",
    "- aprendizagem em si: \n",
    "    - *LogisticRegression*, \n",
    "    - *KNeighborsClassifier*, \n",
    "    - *SVC*, \n",
    "    - *RandomForestClassifier*\n",
    "- construção da sequência de passos a realizar:\n",
    "    - *Pipeline*\n",
    "- avaliação e seleção dos modelos obtidos:\n",
    "    - *ShuffleSplit*,\n",
    "    - *cross_validate*\n",
    "    \n",
    "Algumas dessas funções serão explicadas adiante. Sigamos.\n",
    "\n",
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b5384-0a7a-4009-bd2d-bf6c6c8656d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/madson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product # produto cartesiano de duas listas sem precisar de for aninhados\n",
    "import pandas as pd # manipulação de dataframes\n",
    "import nltk # ferramentas p/ processamento de linguagem natural\n",
    "import numpy as np # manipulação de matrizes, funções matemáticas\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914b1ad-d16a-4753-9e1b-c2a8a98e74e3",
   "metadata": {},
   "source": [
    "## Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf70b45f-1075-4258-956f-d9e9b450a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adquire dados do arquivo produzido na etapa anterior\n",
    "input_path = \"../data/interim/news.csv\"\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Converte as colunas com texto em uma lista\n",
    "corpus = df.text.to_list()\n",
    "\n",
    "# Atribui os valores 1 para notícias verdadeiras e 0 para notícias falsas\n",
    "labels = df.label.replace({\"true\": 1, \"fake\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809f859-8c48-4ee0-a9f5-2665b03be073",
   "metadata": {},
   "source": [
    "## Conversões dos textos\n",
    "\n",
    "### CountVectorizer\n",
    "\n",
    "Esse método de conversão cria uma matriz com a contagem de todas as palavras presentes em todos os textos considerados. Esse método também é chamado de Bag of Words, ou Saco de Palavras.\n",
    "\n",
    "![CountVectorizer](images/count-vectorizer.png)\n",
    "\n",
    "### TfidfVectorizer\n",
    "\n",
    "Esse método de conversão cria uma matriz que considera dois valores: TF e DF. TF ($tf_{i,j}$) é a contagem de uma palavra ($i$) no texto ($j$), tal como é calculada pelo CountVectorizer. Já DF ($df_{i}$) diz respeito à quantidade de textos em que aquela palavra aparece. No cálculo, o valor para uma dada palavra ($w_{i,j}$) é dado por:\n",
    "\n",
    "$ w_{i,j} = tf_{i,j} \\times log(\\frac{N}{df_{i}}) $\n",
    "\n",
    "Em que $N$ é o número total de documentos. Como $df_{i}$ está no denominador do logarítmo, trata-se de uma conversão que considera TF e o inverso de DF, iDF.\n",
    "\n",
    "![CountVectorizer](images/tfidf-vectorizer.png)\n",
    "\n",
    "Em ambos os casos, palavras comuns e sem importância semântica no idioma trabalhado devem ser removidas. Afinal, caso fossem consideradas na conversão TFiDF, as palavras \"de\" e \"desse\" no primeiro texto teriam o mesmo peso da palavra \"corrupção\" e \"suspeito\", com importância semântica superior.\n",
    "\n",
    "Aqui, optamos também por utilizar apenas as 1000 palavras mais frequentes em ambas as conversões, de modo a limitar o número de características para o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf09e2bd-e35e-4cef-8849-85397fb0d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'bow': CountVectorizer(\n",
    "        stop_words = nltk.corpus.stopwords.words('portuguese'),\n",
    "        max_features = 1000\n",
    "    ),\n",
    "    'tfidf': TfidfVectorizer(\n",
    "        stop_words = nltk.corpus.stopwords.words('portuguese'),\n",
    "        max_features = 1000\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0a6d1-c85c-4e5a-952a-8ebd72a042dd",
   "metadata": {},
   "source": [
    "## Modelos de Aprendizagem de Máquina\n",
    "\n",
    "### Regressão Logística\n",
    "\n",
    "A regressão logística, que é um modelo classificador, utiliza uma função logística para calcular as probabilidades de uma notícia ser falsa ou verdadeira. A função logística por trás deste modelo é uma curva sigmoide contendo as probabilidades de classificação em uma determinada categoria (notícia falsa ou verdadeira). A partir disso se encontra um valor limite dentro da curva para que então se obtenham as predições.\n",
    "\n",
    "### KNN\n",
    "\n",
    "Aqui a classificação das notícias em falsas ou verdadeira é feita com base nos K-vizinhos mais próximos (*K-Nearest Neighbors*) a ela. Se utilizamos $K = 10$ e dentre as 10 notícias mais próximas de uma notícia $i$ no nosso espaço dimensional, 6 são falsas e 4 são verdadeiras, esta notícia $i$ será classificada como falsa. No nosso caso utilizamos $K = 21$.\n",
    "\n",
    "### SVC\n",
    "\n",
    "O SVC é um *Support Vector Classifier*, isso é, um algoritmo de classificação que utiliza vetores (dados) como suporte para definir um hiperplano que separe dados de um grupo dos dados de outro grupo. No nosso caso, o SVC busca um hiperplano que separe as matrizes produzidas a partir de notícias falsas daquelas de notícias verdadeiras.\n",
    "\n",
    "O hiperplano pode ser obtido após uma transformação dos dados, na qual eles saem de seu espaço dimensional original, intrínseco, e são levados a um espaço dimensional superior. Essa transformação é feita através através de diversas fórmulas matemáticas para que então o hiperplano ideal - aquele que separa os dados com melhor margem - seja identificado; este é o chamado *kernel trick*.\n",
    "\n",
    "### Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5251981e-4d02-4213-85ed-95af456e4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'logistic regression': LogisticRegression(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=21),\n",
    "    'SVC': SVC(),\n",
    "    'random forest': RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20a6091-4dd7-4c95-b821-41008bdd7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = TruncatedSVD(500)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7e46c1-96a2-4dfc-a337-1782d58a6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "n_splits = 10\n",
    "split = ShuffleSplit(n_splits=n_splits, test_size=.2)\n",
    "for vectorizer, model in product(vectorizers.items(), models.items()):\n",
    "    vectorizer_name, vectorizer_ = vectorizer\n",
    "    model_name, model_ = model\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"vectorizer\", vectorizer_),\n",
    "        (\"pca\", pca),\n",
    "        (\"normalize\", scaler),\n",
    "        (\"model\", model_)\n",
    "    ])    \n",
    "    scores = cross_validate(pipeline, corpus, labels, cv=split, scoring=['accuracy', 'f1'])\n",
    "    scores['model'] = [f\"{vectorizer_name}-{model_name}\"] * n_splits\n",
    "    if not(results):\n",
    "        results = {key: [] for key in scores}\n",
    "    for key in scores:\n",
    "        results[key].extend(scores[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bececb25-cd41-4bb0-bd7c-01b2d40ff34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = (\n",
    "    pd\n",
    "    .DataFrame(results)\n",
    "    .groupby(\"model\")\n",
    "    .agg([np.mean, np.std])\n",
    "    .transpose()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d57768-04a8-479e-ab87-70a7437dcf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bow-KNN</th>\n",
       "      <th>bow-SVC</th>\n",
       "      <th>bow-logistic regression</th>\n",
       "      <th>bow-random forest</th>\n",
       "      <th>tfidf-KNN</th>\n",
       "      <th>tfidf-SVC</th>\n",
       "      <th>tfidf-logistic regression</th>\n",
       "      <th>tfidf-random forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fit_time</th>\n",
       "      <th>mean</th>\n",
       "      <td>5.814648</td>\n",
       "      <td>8.637069</td>\n",
       "      <td>6.292938</td>\n",
       "      <td>21.823260</td>\n",
       "      <td>5.813607</td>\n",
       "      <td>14.061045</td>\n",
       "      <td>6.063270</td>\n",
       "      <td>16.788882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.080802</td>\n",
       "      <td>0.084062</td>\n",
       "      <td>0.187033</td>\n",
       "      <td>0.333607</td>\n",
       "      <td>0.073308</td>\n",
       "      <td>0.339682</td>\n",
       "      <td>0.079474</td>\n",
       "      <td>0.287679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">score_time</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.924707</td>\n",
       "      <td>1.093691</td>\n",
       "      <td>0.654466</td>\n",
       "      <td>0.612344</td>\n",
       "      <td>0.920975</td>\n",
       "      <td>3.191312</td>\n",
       "      <td>0.652346</td>\n",
       "      <td>0.611891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>0.023749</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.037061</td>\n",
       "      <td>0.079363</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>0.015909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">test_accuracy</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.507500</td>\n",
       "      <td>0.952847</td>\n",
       "      <td>0.952292</td>\n",
       "      <td>0.946319</td>\n",
       "      <td>0.500278</td>\n",
       "      <td>0.948194</td>\n",
       "      <td>0.940486</td>\n",
       "      <td>0.914097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.015136</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.007685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">test_f1</th>\n",
       "      <th>mean</th>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.952411</td>\n",
       "      <td>0.951610</td>\n",
       "      <td>0.947615</td>\n",
       "      <td>0.661847</td>\n",
       "      <td>0.949383</td>\n",
       "      <td>0.940806</td>\n",
       "      <td>0.912608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>0.007970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                bow-KNN   bow-SVC  bow-logistic regression  \\\n",
       "fit_time      mean  5.814648  8.637069                 6.292938   \n",
       "              std   0.080802  0.084062                 0.187033   \n",
       "score_time    mean  0.924707  1.093691                 0.654466   \n",
       "              std   0.026855  0.047469                 0.023749   \n",
       "test_accuracy mean  0.507500  0.952847                 0.952292   \n",
       "              std   0.015136  0.003456                 0.005689   \n",
       "test_f1       mean  0.010868  0.952411                 0.951610   \n",
       "              std   0.004602  0.003727                 0.006216   \n",
       "\n",
       "model               bow-random forest  tfidf-KNN  tfidf-SVC  \\\n",
       "fit_time      mean          21.823260   5.813607  14.061045   \n",
       "              std            0.333607   0.073308   0.339682   \n",
       "score_time    mean           0.612344   0.920975   3.191312   \n",
       "              std            0.010742   0.037061   0.079363   \n",
       "test_accuracy mean           0.946319   0.500278   0.948194   \n",
       "              std            0.005947   0.013797   0.003092   \n",
       "test_f1       mean           0.947615   0.661847   0.949383   \n",
       "              std            0.005971   0.012097   0.002667   \n",
       "\n",
       "model               tfidf-logistic regression  tfidf-random forest  \n",
       "fit_time      mean                   6.063270            16.788882  \n",
       "              std                    0.079474             0.287679  \n",
       "score_time    mean                   0.652346             0.611891  \n",
       "              std                    0.017939             0.015909  \n",
       "test_accuracy mean                   0.940486             0.914097  \n",
       "              std                    0.005498             0.007685  \n",
       "test_f1       mean                   0.940806             0.912608  \n",
       "              std                    0.005817             0.007970  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
